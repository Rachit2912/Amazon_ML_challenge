{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rachit2912/Amazon_ML_challenge/blob/main/ml_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_swhAf1rlBo9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a13c401-2a7d-4d95-8ec5-639a3a798a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Amazon_ML_challenge'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 20 (delta 2), reused 20 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (20/20), 4.94 MiB | 6.70 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Rachit2912/Amazon_ML_challenge.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwhKtXVqF9sF",
        "outputId": "ad410bba-3047-45b3-96c2-1e25d5c58822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "                                                          #  fetching image : #\n",
        "def fetch_image(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an error for bad responses\n",
        "        image = Image.open(BytesIO(response.content))\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching image: {e}\")\n",
        "        return None\n",
        "\n",
        "#**   EXTRACTNG TEXT FROM OCR : **#\n",
        "# text = extract_text_with_easyocr(preprocessed_image)\n",
        "# print(text)\n",
        "import requests\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "# import easyocr\n",
        "# os.makedirs('pre_images', exist_ok=True)\n",
        "# os.makedirs('ocr_text', exist_ok=True)\n",
        "!rm -rf ocr_text pre_images\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "\n",
        "                              # Function to rotate the image in different orientations\n",
        "def rotate_image(image, angle):\n",
        "    # Convert PIL image to OpenCV format (np.array)\n",
        "    image_cv = np.array(image)\n",
        "    (h, w) = image_cv.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "\n",
        "    # Perform the rotation\n",
        "    matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    rotated = cv2.warpAffine(image_cv, matrix, (w, h))\n",
        "\n",
        "    return rotated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtQWAQvWTj22",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Process the image URLs from the CSV file\n",
        "import pytesseract\n",
        "def process_images_from_csv(csv_file):\n",
        "    df = pd.read_csv(csv_file)  # Reading the CSV file\n",
        "\n",
        "    # Create directories for preprocessed images if not already present\n",
        "    if not os.path.exists('pre_images'):\n",
        "        os.makedirs('pre_images')\n",
        "\n",
        "    # Add a new column for OCR text if it doesn't exist\n",
        "    if 'ocr_text' not in df.columns:\n",
        "        df['ocr_text'] = ''\n",
        "\n",
        "    # Iterate over each row in the DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        # if index<start:\n",
        "        #   continue\n",
        "\n",
        "        # if index>end:\n",
        "        #   break\n",
        "        image_url = row['image_link']  # Assuming the column is named 'image_link'\n",
        "        image = fetch_image(image_url)\n",
        "\n",
        "\n",
        "        if image is not None:\n",
        "            # Initialize a variable to accumulate the OCR text for all orientations\n",
        "            accumulated_text = \"\"\n",
        "\n",
        "            # Process the image for four different orientations\n",
        "            for angle in [0, 90, 180, 270]:\n",
        "                rotated_image = rotate_image(image, angle)\n",
        "\n",
        "                # Save the preprocessed (rotated) image\n",
        "                # image_save_path = f'pre_images/preprocessed_image_{index}_{angle}.jpg'\n",
        "                # cv2.imwrite(image_save_path, rotated_image)\n",
        "\n",
        "                # Extract OCR text from the rotated image\n",
        "                extracted_text = pytesseract.image_to_string(rotated_image)\n",
        "                # extracted_text = extract_text_with_easyocr(rotated_image)\n",
        "                # extracted_text = api.ocr_url(rotated_image)\n",
        "                # extracted_text = ocr_space_url(url=image_url)\n",
        "\n",
        "                # Append the OCR text for the current orientation\n",
        "                accumulated_text += f\"{extracted_text}\\n\"\n",
        "\n",
        "            # Update the OCR text column in the DataFrame\n",
        "            df.at[index, 'ocr_text'] = accumulated_text.strip()\n",
        "            df.to_csv(csv_file, index=False)\n",
        "            print(f\"Processed image {index} and saved OCR text for all orientations.\")\n",
        "\n",
        "        else:\n",
        "            print(f\"Skipping image {index} due to fetch error.\")\n",
        "\n",
        "    # Save the updated DataFrame back to the CSV file\n",
        "    # df.to_csv(csv_file, index=False)\n",
        "    print(f\"Updated CSV file saved at {csv_file}\")\n",
        "\n",
        "# Example usage\n",
        "# csv_file = '/content/Amazon_ML_challenge/dataset/sample_test.csv'  # Path to your CSV file containing the image URLs\n",
        "csv_file = '/content/Amazon_ML_challenge/dataset/test.csv'\n",
        "process_images_from_csv(csv_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Entity to Unit map with various short forms\n",
        "entity_unit_map = {\n",
        "    \"width\": {\"centimetre\", \"centimetres\", \"cms\", \"cm\", \"foot\", \"feets\", \"fts\", \"'\", \"ft\", \"millimetre\", \"millimetres\", \"mms\", \"mm\", \"metres\", \"metre\", \"m\", \"\\\"\", \"inch\", \"inches\", \"in\", \"yard\", \"yards\", \"yd\", \"yds\"},\n",
        "    \"depth\": {\"centimetre\", \"centimetres\", \"cms\", \"cm\", \"foot\", \"feets\", \"fts\", \"'\", \"ft\", \"millimetre\", \"millimetres\", \"mms\", \"mm\", \"metres\", \"metre\", \"m\", \"\\\"\", \"inch\", \"inches\", \"in\", \"yard\", \"yards\", \"yd\", \"yds\"},\n",
        "    \"height\": {\"centimetre\", \"centimetres\", \"cms\", \"cm\", \"foot\", \"feets\", \"fts\", \"'\", \"ft\", \"millimetre\", \"millimetres\", \"mms\", \"mm\", \"metres\", \"metre\", \"m\", \"\\\"\", \"inch\", \"inches\", \"in\", \"yard\", \"yards\", \"yd\", \"yds\"},\n",
        "    \"item_weight\": {\"milligram\", \"mg\", \"milligrams\", \"kilogram\", \"kg\", \"kgs\", \"kilograms\", \"microgram\", \"micrograms\", \"μg\", \"ug\", \"gram\", \"grams\", \"g\", \"gm\", \"gms\", \"ounce\", \"oz\", \"ton\", \"tonnes\", \"lb\", \"lbs\", \"pound\", \"pounds\"},\n",
        "    \"maximum_weight_recommendation\": {\"milligram\", \"mg\", \"milligrams\", \"kilogram\", \"kg\", \"kgs\", \"kilograms\", \"microgram\", \"micrograms\", \"μg\", \"ug\", \"gram\", \"grams\", \"g\", \"gm\", \"ounce\", \"oz\", \"ton\", \"tonnes\", \"lb\", \"lbs\", \"pound\", \"pounds\"},\n",
        "    \"voltage\": {\"millivolt\", \"millivolts\", \"mV\", \"kilovolt\", \"kilovolts\", \"kV\", \"volt\", \"volts\", \"V\"},\n",
        "    \"wattage\": {\"kilowatt\", \"kilowatts\", \"kW\", \"watt\", \"watts\", \"W\"},\n",
        "    \"item_volume\": {\n",
        "        \"cubic foot\", \"cubic foots\", \"cu ft\", \"cu fts\", \"cufts\", \"cuft\", \"microlitre\", \"μL\", \"microlitres\", \"cup\", \"cups\", \"fluid ounce\", \"fluid ounces\", \"fl oz\", \"floz\", \"centilitre\", \"cl\", \"centilitres\",\n",
        "        \"imperial gallon\", \"imperial gallons\", \"gal\", \"pint\", \"pints\", \"pt\", \"decilitre\", \"decilitres\", \"dl\", \"litre\", \"litres\", \"ltr\", \"l\", \"millilitre\", \"ml\", \"millilitres\", \"mls\",\n",
        "        \"quart\", \"quarts\", \"qt\", \"cubic inch\", \"cubicinch\", \"cubic inches\", \"cubicinches\", \"cuin\", \"cu in\", \"gallon\", \"gallons\"}\n",
        "}\n",
        "\n",
        "# Function to dynamically build regex patterns that handle both single values and ranges\n",
        "def build_regex_patterns(entity_unit_map):\n",
        "    patterns = {}\n",
        "    for entity, units in entity_unit_map.items():\n",
        "        # Create a regex pattern that captures both single values and ranges (e.g., 20-30)\n",
        "        unit_pattern = r'|'.join(units)  # Join all units into a regex alternation pattern\n",
        "        # Regex pattern that matches numbers or ranges (e.g., \"20\", \"20-30\") followed by a unit\n",
        "        patterns[entity] = rf'((?:\\d+\\.?\\d*|\\d+-\\d+\\.?\\d*)\\s*({unit_pattern}))'\n",
        "    return patterns\n",
        "\n",
        "def extract_dimensions(text, entity, patterns):\n",
        "    if any(e in entity for e in ['width', 'height', 'depth']):\n",
        "        dimension_pattern = patterns['height']  # Assuming height, width, and depth have the same pattern\n",
        "        matches = re.findall(dimension_pattern, text, re.IGNORECASE)\n",
        "\n",
        "        if matches:\n",
        "            # Parse matches to extract numeric values and units\n",
        "            parsed_matches = []\n",
        "            for value, unit in matches:\n",
        "                numeric_value = re.sub(r'[^\\d\\.]', '', value)\n",
        "                if numeric_value:\n",
        "                    parsed_matches.append((float(numeric_value), unit))\n",
        "\n",
        "            # Remove redundancy by converting to set and back to list\n",
        "            parsed_matches = list(set(parsed_matches))\n",
        "\n",
        "            # Sort the parsed matches in descending order (max to min)\n",
        "            sorted_values = sorted(parsed_matches, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "            if len(sorted_values) == 1:\n",
        "                # If only one value is found, return that value as the requested entity\n",
        "                return f\"{sorted_values[0][0]} {sorted_values[0][1]}\" if entity in ['height', 'width', 'depth'] else None\n",
        "            elif len(sorted_values) == 2:\n",
        "                # If two values are found, max is height, min is width or depth\n",
        "                if entity == 'height':\n",
        "                    return f\"{sorted_values[0][0]} {sorted_values[0][1]}\"\n",
        "                elif entity == 'width' or entity == 'depth':\n",
        "                    return f\"{sorted_values[1][0]} {sorted_values[1][1]}\"\n",
        "            elif len(sorted_values) == 3:\n",
        "                # If three values are found, max is height, 2nd max is depth, and min is width\n",
        "                if entity == 'height':\n",
        "                    return f\"{sorted_values[0][0]} {sorted_values[0][1]}\"\n",
        "                elif entity == 'depth':\n",
        "                    return f\"{sorted_values[1][0]} {sorted_values[1][1]}\"\n",
        "                elif entity == 'width':\n",
        "                    return f\"{sorted_values[2][0]} {sorted_values[2][1]}\"\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "# Function to extract weights based on keywords like \"net weight\" and return the larger value if keywords aren't present\n",
        "def extract_weight_entity(text, patterns):\n",
        "    if 'item_weight' in patterns:\n",
        "        pattern = patterns['item_weight']\n",
        "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "        # print(matches)\n",
        "\n",
        "        if matches:\n",
        "            parsed_matches = []\n",
        "            for value, unit in matches:\n",
        "                if '-' in value:\n",
        "                  continue\n",
        "                numeric_value = re.sub(r'[^\\d\\.]', '', value)\n",
        "                if numeric_value:\n",
        "                    parsed_matches.append((float(numeric_value), unit))\n",
        "\n",
        "            if parsed_matches:\n",
        "                max_value = max(parsed_matches, key=lambda x: x[0])\n",
        "                return f\"{max_value[0]} {max_value[1]}\"\n",
        "\n",
        "    return None\n",
        "\n",
        "# Function to extract item volume\n",
        "def extract_item_volume(text, patterns):\n",
        "    if 'item_volume' in patterns:\n",
        "        pattern = patterns['item_volume']\n",
        "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "\n",
        "        if matches:\n",
        "            parsed_matches = []\n",
        "            for value, unit in matches:\n",
        "                numeric_value = re.sub(r'[^\\d\\.]', '', value)\n",
        "                if numeric_value:\n",
        "                    parsed_matches.append((float(numeric_value), unit))\n",
        "\n",
        "            if parsed_matches:\n",
        "                max_value = max(parsed_matches, key=lambda x: x[0])\n",
        "                return f\"{max_value[0]} {max_value[1]}\"\n",
        "\n",
        "    return None\n",
        "\n",
        "# Function to extract entities (including ranges) from text\n",
        "def extract_entity(text, entity, patterns):\n",
        "    if entity == 'item_weight':\n",
        "        return extract_weight_entity(text, patterns)\n",
        "\n",
        "    if entity == 'maximum_weight_recommendation':\n",
        "        if 'maximum_weight_recommendation' in patterns:\n",
        "            pattern = patterns['maximum_weight_recommendation']\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            # print(matches)\n",
        "            if matches:\n",
        "                ranges = [match for match in matches if '-' in match[0]]\n",
        "                # print(ranges)\n",
        "                if len(ranges)!=0:\n",
        "                    # value = value.split(\"\")\n",
        "                    # ans = ranges[0][0]\n",
        "                    # ans = ans.split(\" \")\n",
        "                    # unit = ans[1]\n",
        "                    # ans = ans[0]\n",
        "                    # print(\"here\",ranges,ans,unit)\n",
        "                    return  ''\n",
        "\n",
        "                parsed_matches = []\n",
        "                for value, unit in matches:\n",
        "                    numeric_value = re.sub(r'[^\\d\\.]', '', value)\n",
        "                    if numeric_value:\n",
        "                        parsed_matches.append((float(numeric_value), unit))\n",
        "\n",
        "                if parsed_matches:\n",
        "                    max_value = max(parsed_matches, key=lambda x: x[0])\n",
        "                    return f\"{max_value[0]} {max_value[1]}\"\n",
        "\n",
        "    if entity == 'voltage':\n",
        "        if 'voltage' in patterns:\n",
        "            pattern = patterns['voltage']\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                parsed_matches = []\n",
        "                for value, unit in matches:\n",
        "                    numeric_value = re.sub(r'[^\\d\\.]', '', value)\n",
        "                    if numeric_value:\n",
        "                        parsed_matches.append((float(numeric_value), unit))\n",
        "\n",
        "                if parsed_matches:\n",
        "                    max_value = max(parsed_matches, key=lambda x: x[0])\n",
        "                    return f\"{max_value[0]} {max_value[1]}\"\n",
        "\n",
        "    if entity == 'wattage':\n",
        "        if 'wattage' in patterns:\n",
        "            pattern = patterns['wattage']\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                parsed_matches = []\n",
        "                for value, unit in matches:\n",
        "                    numeric_value = re.sub(r'[^\\d\\.]', '', value)\n",
        "                    if numeric_value:\n",
        "                        parsed_matches.append((float(numeric_value), unit))\n",
        "\n",
        "                if parsed_matches:\n",
        "                    max_value = max(parsed_matches, key=lambda x: x[0])\n",
        "                    return f\"{max_value[0]} {max_value[1]}\"\n",
        "\n",
        "    if entity in ['height', 'width', 'depth']:\n",
        "        return extract_dimensions(text, entity, patterns)\n",
        "\n",
        "    if entity == 'item_volume':\n",
        "        return extract_item_volume(text, patterns)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Example usage:\n",
        "patterns = build_regex_patterns(entity_unit_map)\n",
        "sample_text = \"30-25 kgs 60 kgs\"\n",
        "\n",
        "# Test the dimension extraction\n",
        "height = extract_entity(sample_text, 'item_weight', patterns)\n",
        "# width = extract_entity(sample_text, 'width', patterns)\n",
        "# depth = extract_entity(sample_text, 'depth', patterns)\n",
        "\n",
        "# print(height)\n",
        "# print(width)\n",
        "# print(depth)\n",
        "#"
      ],
      "metadata": {
        "id": "OLw3rE9IkR9l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## updated :\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Define the unit conversion map with escaping for special characters\n",
        "unit_conversion_map = {\n",
        "    \"centimetres\": \"centimetre\",\n",
        "    \"cms\": \"centimetre\",\n",
        "    \"cm\": \"centimetre\",\n",
        "    \"feets\": \"foot\",\n",
        "    \"fts\": \"foot\",\n",
        "    \"'\": \"foot\",\n",
        "    \"ft\": \"foot\",\n",
        "    \"millimetres\": \"millimetre\",\n",
        "    \"mms\": \"millimetre\",\n",
        "    \"mm\": \"millimetre\",\n",
        "    \"metres\": \"metre\",\n",
        "    \"m\": \"metre\",\n",
        "    \"\\\"\": \"inch\",\n",
        "    \"inches\": \"inch\",\n",
        "    \"in\": \"inch\",\n",
        "    \"yards\": \"yard\",\n",
        "    \"yds\": \"yard\",\n",
        "    \"yd\": \"yard\",\n",
        "    \"milligrams\": \"milligram\",\n",
        "    \"mg\": \"milligram\",\n",
        "    \"kilograms\": \"kilogram\",\n",
        "    \"kgs\": \"kilogram\",\n",
        "    \"kg\": \"kilogram\",\n",
        "    \"micrograms\": \"microgram\",\n",
        "    \"μg\": \"microgram\",\n",
        "    \"ug\": \"microgram\",\n",
        "    \"grams\": \"gram\",\n",
        "    \"gm\": \"gram\",\n",
        "    \"gms\": \"gram\",\n",
        "    \"g\": \"gram\",\n",
        "    \"oz\": \"ounce\",\n",
        "    \"lbs\": \"pound\",\n",
        "    \"lb\": \"pound\",\n",
        "    \"pounds\": \"pound\",\n",
        "    \"tonnes\": \"ton\",\n",
        "    \"tons\": \"ton\",\n",
        "    \"millivolts\": \"millivolt\",\n",
        "    \"mV\": \"millivolt\",\n",
        "    \"kilovolts\": \"kilovolt\",\n",
        "    \"kV\": \"kilovolt\",\n",
        "    \"volts\": \"volt\",\n",
        "    \"V\": \"volt\",\n",
        "    \"kilowatts\": \"kilowatt\",\n",
        "    \"kW\": \"kilowatt\",\n",
        "    \"watts\": \"watt\",\n",
        "    \"W\": \"watt\",\n",
        "    \"cubic foots\": \"cubic foot\",\n",
        "    \"cu fts\": \"cubic foot\",\n",
        "    \"cufts\": \"cubic foot\",\n",
        "    \"cuft\": \"cubic foot\",\n",
        "    \"microlitres\": \"microlitre\",\n",
        "    \"μL\": \"microlitre\",\n",
        "    \"cups\": \"cup\",\n",
        "    \"fluid ounces\": \"fluid ounce\",\n",
        "    \"fl\":\"fluid\",\n",
        "    \"fl oz\": \"fluid ounce\",\n",
        "    \"floz\": \"fluid ounce\",\n",
        "    \"centilitres\": \"centilitre\",\n",
        "    \"cl\": \"centilitre\",\n",
        "    \"imperial gallons\": \"imperial gallon\",\n",
        "    \"gal\": \"imperial gallon\",\n",
        "    \"pints\": \"pint\",\n",
        "    \"pt\": \"pint\",\n",
        "    \"decilitres\": \"decilitre\",\n",
        "    \"dl\": \"decilitre\",\n",
        "    \"litres\": \"litre\",\n",
        "    \"ltr\": \"litre\",\n",
        "    \"l\": \"litre\",\n",
        "    \"millilitres\": \"millilitre\",\n",
        "    \"mls\": \"millilitre\",\n",
        "    \"ml\": \"millilitre\",\n",
        "    \"quarts\": \"quart\",\n",
        "    \"qt\": \"quart\",\n",
        "    \"cubic inches\": \"cubic inch\",\n",
        "    \"cubicinches\": \"cubic inch\",\n",
        "    \"cuin\": \"cubic inch\",\n",
        "    \"cu in\": \"cubic inch\",\n",
        "    \"gallons\": \"gallon\"\n",
        "}\n",
        "\n",
        "def convert_units(prediction, unit_conversion_map):\n",
        "    if not prediction:\n",
        "        return \"\"\n",
        "\n",
        "    # Explicitly handle single and double quotes\n",
        "    prediction = prediction.replace(\"'\", \"foot\").replace(\"\\\"\", \"inch\")\n",
        "\n",
        "    # Convert each short form or symbol in the prediction\n",
        "    for short_form, full_form in unit_conversion_map.items():\n",
        "        # Escape special characters for regex\n",
        "        escaped_short_form = re.escape(short_form)\n",
        "        # Replace short form and symbols with full form\n",
        "        prediction = re.sub(rf'\\b{escaped_short_form}\\b', full_form, prediction, flags=re.IGNORECASE)\n",
        "\n",
        "    return prediction\n",
        "\n",
        "def process_csv(input_csv_path, output_csv_path):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv(input_csv_path)\n",
        "\n",
        "    # Build regex patterns for each entity (assuming this function exists)\n",
        "    patterns = build_regex_patterns(entity_unit_map)\n",
        "\n",
        "    # Extract and update the predictions\n",
        "    df['prediction'] = df.apply(lambda row: extract_entity(str(row['ocr_text']), str(row['entity_name']), patterns), axis=1)\n",
        "\n",
        "    # Convert short forms and symbols to full form unit names\n",
        "    df['prediction'] = df['prediction'].apply(lambda pred: convert_units(pred, unit_conversion_map).lower())\n",
        "\n",
        "    # Replace NaN or None values in 'prediction' with an empty string\n",
        "    df['prediction'].fillna('', inplace=True)\n",
        "\n",
        "    # Create a new DataFrame with only 'index' and 'prediction' columns\n",
        "    output_df = df[['index', 'prediction']]\n",
        "\n",
        "    # Save the updated DataFrame to a new CSV file\n",
        "    print(\"index\",df['index'])\n",
        "    output_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# # Example usage\n",
        "input_csv_path = '/content/Amazon_ML_challenge/dataset/test.csv'\n",
        "output_csv_path = '/content/Amazon_ML_challenge/dataset/test_output.csv'\n",
        "process_csv(input_csv_path, output_csv_path)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/Amazon_ML_challenge/dataset/test_output.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "_519IS7YkT-M"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}